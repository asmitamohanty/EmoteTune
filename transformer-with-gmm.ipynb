{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10165440,"sourceType":"datasetVersion","datasetId":6225532},{"sourceId":10175551,"sourceType":"datasetVersion","datasetId":6269525},{"sourceId":10185717,"sourceType":"datasetVersion","datasetId":6158297}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchinfo import summary\nimport torch.optim as optim\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom sklearn.mixture import GaussianMixture","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import defaultdict","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = 'cuda'\n    print(\"GPU is available. Using GPU.\")\nelse:\n    device = 'cpu'\n    print(\"GPU is not available. Using CPU.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import math\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=500, dropout=0.1):\n        super(PositionalEncoding, self).__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len).unsqueeze(1).float()\n        div_term = torch.pow(10000, torch.arange(0, d_model, 2).float() / d_model)\n        pe[:, 0::2] = torch.sin(position / div_term)  \n        pe[:, 1::2] = torch.cos(position / div_term)  \n        self.register_buffer(\"pe\", pe.unsqueeze(0))  \n\n    def forward(self, x):\n        x = x + self.pe[:x.size(0), :]\n        return self.dropout(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scaler = torch.amp.GradScaler(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TransformerEncoder(nn.Module):\n    def __init__(self, input_dim, d_model, max_len, num_heads, num_layers):\n        super(TransformerEncoder, self).__init__()\n        self.d_model = d_model\n        self.max_len = max_len\n        #self.num_layers = num_layers\n        #self.num_heads = num_heads\n        #self.input_dim = input_dim\n        self.encoder_layer = nn.TransformerEncoderLayer(self.d_model, \n                                                        num_heads)\n        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, \n                                                         num_layers)\n        #self.pos_encoder = PositionalEncoding(self.d_model, self.max_len)\n        self.pos_encoder = nn.Parameter(torch.randn(1, self.max_len, \n                                                    input_dim))  \n        self.linear_in = nn.Linear(input_dim, self.d_model)\n        self.linear_out = nn.Linear(self.d_model, 64)\n\n    def forward(self, src):\n        src = self.linear_in(src) * math.sqrt(self.d_model)\n        src = src + self.pos_encoder[:, :src.size(1), :]\n        #src = self.pos_encoder(src)\n        output = self.transformer_encoder(src)\n        output = self.linear_out(output[:, 0, :])\n        return output\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TransformerEncoder2(nn.Module):\n    def __init__(self, input_dim, d_model, num_heads, num_layers):\n        super(TransformerEncoder2, self).__init__()\n        encoder_layer = nn.TransformerEncoderLayer(d_model, num_heads)\n        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n        self.pos_encoder = PositionalEncoding(d_model)\n        #self.pos_encoder = nn.Parameter(torch.randn(1, 500, input_dim))  \n        self.linear_in = nn.Linear(input_dim, d_model)\n        self.linear_out = nn.Linear(d_model, 64)\n\n    def forward(self, src):\n        src = self.linear_in(src) * math.sqrt(self.d_model)\n        src = self.pos_encoder(src)\n        output = self.transformer_encoder(src)\n        output = self.linear_out(output[:, 0, :])\n        return output","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model, optimizer, criterion, device, max_grad_norm=1.0):\n        self.model = model.to(device)\n        self.optimizer = optimizer\n        self.criterion = criterion\n        self.device = device\n        self.max_grad_norm = max_grad_norm\n\n    def train_step(self, x):\n        x = x.to(self.device)\n\n       \n        x = (x - x.mean(dim=0)) / (x.std(dim=0) + 1e-6)\n\n        self.optimizer.zero_grad()\n        output = self.model(x)\n        loss = self.criterion(output, output.mean(dim=0))  \n\n        if not torch.isfinite(loss):  \n            print(\"Warning: Loss is not finite. Skipping this step.\")\n            return float('nan')\n\n        loss.backward()\n        \n       \n        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n        self.optimizer.step()\n\n        return loss.item()\n\n    def train(self, dataloader, epochs):\n        for epoch in range(epochs):\n            torch.cuda.empty_cache()  \n            initial_memory = torch.cuda.memory_allocated(device)\n            print(f\"Epoch {epoch + 1} - Initial GPU memory: {initial_memory / 1e6} MB\")\n\n            print(f\"Epoch [{epoch + 1}/{epochs}]\")\n            total_loss = 0\n            valid_steps = 0\n            for batch in dataloader:\n                loss = self.train_step(batch[0])\n                if torch.isfinite(torch.tensor(loss)):  \n                    total_loss += loss\n                    valid_steps += 1\n            avg_loss = total_loss / valid_steps if valid_steps > 0 else float('nan')\n            print(f\"Loss: {avg_loss:.4f}\")\n            torch.cuda.empty_cache()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"openl3_train_embeddings_path = '/kaggle/input/openl3-embeddings/openl3_audio_embeddings_final_train_11-12-24.pt'\nopenl3_train_labels_path = '/kaggle/input/openl3-embeddings/openl3_labels_final_train_11-12-24.pt'\nopenl3_val_embeddings_path = '/kaggle/input/openl3-embeddings/openl3_audio_embeddings_final_validation_11-12-24.pt'\nopenl3_val_labels_path = '/kaggle/input/openl3-embeddings/openl3_labels_final_validation_11-12-24.pt'\nopenl3_test_embeddings_path = '/kaggle/input/openl3-embeddings/openl3_audio_embeddings_final_test_11-12-24.pt'\nopenl3_test_labels_path = '/kaggle/input/openl3-embeddings/openl3_labels_final_test_11-12-24.pt'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_embeddings = torch.load(openl3_train_embeddings_path, \n                              map_location=device, \n                             weights_only=True)  \ntest_embeddings = torch.load(openl3_test_embeddings_path, \n                              map_location=device, \n                             weights_only=True)    \nval_embeddings = torch.load(openl3_val_embeddings_path, \n                              map_location=device, \n                             weights_only=True)      \n\n\nall_embeddings = torch.cat((train_embeddings, test_embeddings, val_embeddings), dim=0)\nprint(all_embeddings.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nembeddings = all_embeddings\nnum_samples, num_channels, num_seq_lengths, audio_size = all_embeddings.shape\nprint(num_samples, num_channels, num_seq_lengths, audio_size)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nembeddings = embeddings.reshape(num_samples, num_seq_lengths, audio_size)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"embeddings.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nmodel = TransformerEncoder(input_dim=audio_size, d_model=audio_size, max_len = num_seq_lengths, num_heads=4, num_layers=2)\noptimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay = 1e-5)\ncriterion = nn.MSELoss()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"summary(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndataset = torch.utils.data.TensorDataset(embeddings)\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(dataset[0][0].shape)\nprint(len(dataset))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Train Model","metadata":{}},{"cell_type":"code","source":"\ntrainer = Trainer(model, optimizer, criterion, device)\ntrainer.train(dataloader, 5)\n\n\nmodel.eval()\nwith torch.no_grad():\n    final_output = model(embeddings.to(device)).cpu().numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), \"transformer_model.pth\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_output","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Re-load saved model","metadata":{}},{"cell_type":"code","source":"model_path = '/kaggle/input/moodtheme-1/transformer_model.pth'\nmodel.load_state_dict(torch.load(model_path, weights_only=True))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nmodel.eval()\nwith torch.no_grad():\n    saved_final_output = model(embeddings.to(device)).cpu().numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(saved_final_output)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def audio_filepath_labels(input_tsv_file):\n    df = pd.read_csv(input_tsv_file, sep='\\t', header=None, names=['file', 'label'])\n    if df.iloc[0, 0] == \"PATH\":\n        df = df.drop(index=0).reset_index(drop=True)\n    \n    df['name'] = df['file'].apply(lambda x: x.split('/')[-1])  \n    \n    \n    name_to_label = dict(zip(df['name'], df['label']))\n    \n    \n    final_data = []\n    \n   \n    for root, dirs, files in os.walk(input_folder):\n        #print(root)\n        for file in files:\n            if file.endswith('.mp3'):\n                name = file.replace('low.','') #os.path.splitext(file)[0]  \n                #print(\"name:\", name)\n                if name in name_to_label:\n                    full_path = os.path.join(root, file)\n                    label = name_to_label[name]\n                    #print(full_path, label)\n                    final_data.append([full_path, label])  \n    \n    \n    final_df_ = pd.DataFrame(final_data, columns=['audio_file_path', 'label'])\n    \n    \n    output_file = '/kaggle/working/audio_files_with_labels.tsv'\n    #final_df.to_csv(output_file, sep='\\t', index=False)\n    \n    print(f\"Final file generated: {output_file}\")\n    return final_df_","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tsv_file = \"/kaggle/input/moodtheme-1/final_mood_labels.tsv\"\ninput_folder = \"/kaggle/input/raw-00-01-02-filtered-files\"\nmulti_tsv_file = \"/kaggle/input/moodtheme-1/final_multi_mood_labels.tsv\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_df = audio_filepath_labels(tsv_file)\nmulti_mood_final_df = audio_filepath_labels(multi_tsv_file)\nprint(\"Broader 4-labeled dataset shape:\", final_df.shape)\nprint(\"Multi-labeled dataset shape:\", multi_mood_final_df.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multi_mood_final_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Multi-labeled dataset","metadata":{}},{"cell_type":"code","source":"multi_label_encoder = LabelEncoder()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multi_en_df = multi_mood_final_df.copy()  \n\n\nmulti_en_df['label_encoded'] = multi_label_encoder.fit_transform(multi_en_df['label'])\nmulti_en_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multi_en_df['label_encoded'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def display_top_class_counts(df, top_k = None):\n    value_counts = df['label_encoded'].value_counts().reset_index()\n    value_counts.columns = ['label_encoded', 'count']\n    \n    \n    encoding_to_label = df.drop_duplicates(subset=['label_encoded'])[['label_encoded', 'label']].set_index('label_encoded')\n    value_counts['label'] = value_counts['label_encoded'].map(encoding_to_label['label'])\n    \n    \n    #print(value_counts)\n    x_counts = value_counts['label']\n    y_counts = value_counts['count']\n    if top_k:\n        x_counts = value_counts['label'][:top_k]\n        y_counts = value_counts['count'][:top_k]\n    \n    plt.figure(figsize=(10, 6))\n    plt.bar(x_counts, y_counts, color='skyblue')\n    plt.xlabel('Label')\n    plt.ylabel('Count')\n    plt.title('Label Encoding vs Actual Label Counts')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n    return value_counts","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multi_value_counts = display_top_class_counts(multi_en_df, 10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multi_value_counts.head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multi_clusters = len(list(np.unique(multi_en_df['label_encoded'])))\nprint(multi_clusters)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def run_GMM(model_output, num_clusters):   \n    \n    gmm = GaussianMixture(n_components=num_clusters, random_state=0)\n    gmm.fit(model_output)\n    \n    \n    probabilities = gmm.predict_proba(model_output)\n    \n    \n    predicted_labels = np.argmax(probabilities, axis=1)\n    \n    \n    return gmm, probabilities, predicted_labels","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multi_gmm, multi_probs, multi_preds = run_GMM(saved_final_output, multi_clusters)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multi_gmm_counts = np.unique(multi_preds, return_counts=True)\n\n\nfor cluster, count in zip(multi_gmm_counts[0], multi_gmm_counts[1]):\n    print(f\"Cluster {cluster}: {count} samples\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def cluster_to_label(gmm_model, gmm_probs, actual_labels):\n    \n    cluster_to_true_label_ = {}\n    \n    \n    for cluster in range(gmm_model.n_components):\n        \n        cluster_indices = np.where(np.argmax(gmm_probs, axis=1) == cluster)[0]\n        \n        true_labels_cluster = actual_labels[cluster_indices]\n        \n        \n        label_probabilities = []\n        for i in cluster_indices:\n            \n            sample_probs = gmm_probs[i]  \n            \n            \n            true_label = actual_labels[i]  \n            \n            label_probabilities.append((true_label, sample_probs))\n    \n        \n        cluster_to_true_label_[cluster] = label_probabilities\n        #print(f'Cluster {cluster}: {label_probabilities}')\n    \n    \n    return cluster_to_true_label_","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multi_true_labels = multi_en_df['label_encoded'].values\nprint(len(multi_true_labels))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multi_cluster_to_label = cluster_to_label(multi_gmm, multi_probs, multi_true_labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multi_cluster_to_label.keys()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def final_label_mapping(cluster_to_true_label_):\n    \n    final_cluster_to_true_label_ = {}  \n    cluster_to_tie_breaker_ = defaultdict(list)  \n    \n    \n    for cluster, label_probabilities in cluster_to_true_label_.items():\n        most_probable_label = None\n        max_probability = -1\n        label_prob_dict = defaultdict(list)  \n        \n        \n        for true_label, probs in label_probabilities:\n            avg_prob = np.mean(probs)  \n            \n            \n            label_prob_dict[true_label] = avg_prob\n            \n            \n            if avg_prob > max_probability:\n                most_probable_label = true_label\n                max_probability = avg_prob\n                cluster_to_tie_breaker_[cluster] = [(true_label, avg_prob)]  \n            elif avg_prob == max_probability:\n                cluster_to_tie_breaker_[cluster].append((true_label, avg_prob))  \n    \n        \n        final_cluster_to_true_label_[cluster] = most_probable_label\n    return final_cluster_to_true_label_, cluster_to_tie_breaker_","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multi_final_cluster_to_true, multi_cluster_to_tie = final_label_mapping(multi_cluster_to_label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Cluster to True Label Mapping (Most Probable):\", multi_final_cluster_to_true)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nmulti_final_predicted_labels = []\nfor cluster in multi_preds:\n    \n    true_label = multi_final_cluster_to_true[cluster]\n    multi_final_predicted_labels.append(true_label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"top_k = 10\nmulti_unique, multi_counts = np.unique(multi_true_labels, return_counts=True)\nmulti_top_k_labels = multi_unique[np.argsort(-multi_counts)[:10]]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multi_top_k_labels","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nmulti_cm = confusion_matrix(multi_true_labels, multi_final_predicted_labels, labels=multi_top_k_labels)\n\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(multi_cm, annot=True, fmt='g', cmap='Blues', xticklabels=multi_top_k_labels, yticklabels=multi_top_k_labels)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multi_label_report = classification_report(multi_true_labels, multi_final_predicted_labels)\n\n\nprint(multi_label_report)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4-labeled Dataset","metadata":{}},{"cell_type":"code","source":"\nen_df = final_df.copy()  \n\n\nlabel_encoder = LabelEncoder()\nen_df['label_encoded'] = label_encoder.fit_transform(en_df['label'])\nen_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"broad_value_counts = display_top_class_counts(en_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"en_df['label_encoded'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.mixture import GaussianMixture\n\n\ngmm = GaussianMixture(n_components=4, random_state=0)\ngmm.fit(final_output)\n\n\nprobabilities = gmm.predict_proba(final_output)\n\n\npredicted_labels = np.argmax(probabilities, axis=1)\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gmm_counts = np.unique(predicted_labels, return_counts=True)\n\n\nfor cluster, count in zip(gmm_counts[0], gmm_counts[1]):\n    print(f\"Cluster {cluster}: {count} samples\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\n\n\njoblib.dump(gmm, 'gmm_model.pkl')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"true_labels = en_df['label_encoded'].values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\ncluster_to_true_label = {}\n\n\nfor cluster in range(gmm.n_components):\n    \n    cluster_indices = np.where(np.argmax(probabilities, axis=1) == cluster)[0]\n    \n    \n    true_labels_cluster = true_labels[cluster_indices]\n    \n    \n    label_probabilities = []\n    for i in cluster_indices:\n        \n        sample_probs = probabilities[i]  \n        \n        \n        true_label = true_labels[i]  \n        \n        label_probabilities.append((true_label, sample_probs))\n\n    \n    cluster_to_true_label[cluster] = label_probabilities\n\n\nprint(\"Cluster to True Label Mapping (without majority voting):\")\n#print(cluster_to_true_label)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cluster_to_true_label[0][:5]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import defaultdict\n\n\n\nfinal_cluster_to_true_label = {}  \ncluster_to_tie_breaker = defaultdict(list)  \n\n\nfor cluster, label_probabilities in cluster_to_true_label.items():\n    most_probable_label = None\n    max_probability = -1\n    label_prob_dict = defaultdict(list)  \n    \n    \n    for true_label, probs in label_probabilities:\n        avg_prob = np.mean(probs)  \n        \n        \n        label_prob_dict[true_label] = avg_prob\n        \n        \n        if avg_prob > max_probability:\n            most_probable_label = true_label\n            max_probability = avg_prob\n            cluster_to_tie_breaker[cluster] = [(true_label, avg_prob)]  \n        elif avg_prob == max_probability:\n            cluster_to_tie_breaker[cluster].append((true_label, avg_prob))  \n\n    \n    final_cluster_to_true_label[cluster] = most_probable_label\n\n\nprint(\"Cluster to True Label Mapping (Most Probable):\", final_cluster_to_true_label)\nprint(\"Cluster to True Label Tie Breakers:\", cluster_to_tie_breaker)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfinal_predicted_labels = []\nfor cluster in predicted_labels:\n    \n    true_label = final_cluster_to_true_label[cluster]\n    final_predicted_labels.append(true_label)\n\n\ncm = confusion_matrix(true_labels, final_predicted_labels)\n\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=np.unique(true_labels), yticklabels=np.unique(true_labels))\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nreport = classification_report(true_labels, final_predicted_labels, zero_division=0)\n\n\nprint(report)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}